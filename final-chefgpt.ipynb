{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25db6af5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Research Question\n",
    "Can we train a neural network to balance nutrition and flavour in order to classify and suggest food ingredients for existing recipes?\n",
    "\n",
    "### Problem Context\n",
    "The growing interest in personalized nutrition and recipe generation has led to an increasing demand for systems that can automatically suggest ingredients based on a combination of factors like nutritional content and flavour compatibility. However, balancing these two factors when suggesting ingredients remains a challenging task, especially when working with unstructured data from recipes and ingredient databases. This research explores the possibility of using deep learning to automate this process.\n",
    "\n",
    "### Objective\n",
    "In this project, we aim to develop a model that can suggest the best ingredients for existing recipes, considering both flavour and nutritional requirements. We hypothesize that by combining data from a flavour dataset (detailing the overlap of molecular components between ingredients) and a nutritional dataset (providing macronutrient distributions), we can train a neural network to make accurate ingredient suggestions.\n",
    "\n",
    "### Data Sources\n",
    "We used three external datasets to build our model:\n",
    "1. **FlavourDB2**: A molecular flavour database that contains information on over 900 food ingredients. Pairwise flavour scores between ingredients are quantified by the amount of overlapping molecules, suggesting how well they would pair in recipes (source: [FlavourDB2](https://cosylab.iiitd.edu.in/flavordb2/)).\n",
    "2. **NEVO Database**: Managed by the National Institute for Public Health and the Environment (RIVM), this dataset provides detailed nutritional information on foods, including energy, macronutrients, vitamins, and minerals (source: [NEVO](https://www.rivm.nl/en)).\n",
    "3. **Recipe Dataset**: A dataset of approximately 125,000 online recipes scraped from various food websites. Each recipe includes a title, list of ingredients, measurements, and preparation instructions (source: [Eight Portions](https://eightportions.com/datasets/Recipes/#fn:1)).\n",
    "\n",
    "Additionally, we used a pre-trained tokenizer from a BERT model fine-tuned on food items to process ingredient lists: [FoodBaseBERT-NER](https://huggingface.co/Dizex/FoodBaseBERT-NER). This tokenizer helped us efficiently handle ingredient names and their semantic representations in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ee5ab",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "This section details the data preprocessing, the model architecture, the loss function, and the key performance metrics used in this study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcae6fb",
   "metadata": {},
   "source": [
    "### Data Source and Preprocessing\n",
    "For this project, we combined three key datasets:\n",
    "1. **FlavourDB2**: Contains molecular data for 900+ ingredients, with pairwise flavour scores based on molecular overlap between ingredients. This allows us to quantify how well two ingredients would pair based on their molecular composition.\n",
    "2. **NEVO**: Provides nutritional data for various food items, including macronutrient breakdown (carbs, fats, proteins), vitamins, and minerals, which we used to ensure the nutritional balance in our ingredient recommendations.\n",
    "3. **Recipe Dataset**: A collection of 125,000 recipes from various websites. From this, we extracted ingredient lists and used them to train our model to predict the most suitable ingredients based on flavour and nutrition.\n",
    "\n",
    "We cleaned the datasets by aligning ingredient names, ensuring consistency between the flavour and nutrition datasets. Fuzzy matching was used to identify and correct discrepancies (e.g., 'butter' vs. 'peanut butter').\n",
    "\n",
    "The recipe dataset was preprocessed by identifying and extracting ingredient lists from each recipe. We then computed a loss based on the overlap of molecules (flavour) and nutritional balance (50% carbs, 30% fat, 20% protein)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ae14e",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "We designed a custom deep learning model for the task, focusing on processing ingredient lists and computing ingredient scores based on flavour and nutrition. The architecture includes a mix of embedding layers, convolutional layers for feature extraction, and fully connected layers for classification.\n",
    "\n",
    "#### Model Description\n",
    "1. **Embedding Layer**: Converts the ingredient text into dense representations using embeddings.\n",
    "2. **Convolutional Layers**: Two 1D convolutional layers process the tokenized ingredient list, learning patterns related to ingredient composition.\n",
    "3. **Pooling Layer**: MaxPooling reduces the dimensionality of the feature maps.\n",
    "4. **Fully Connected Layers**: Perform the final classification, with dropout and batch normalization applied to prevent overfitting.\n",
    "5. **Output Layers**: Two outputs are generated: one for the ingredient prediction (`ingredient_output`) and one for the ingredient score (`score_output`). The `ingredient_output` uses a softmax activation function to predict the ingredient, and the `score_output` uses a linear activation for the 'total_loss' score.\n",
    "\n",
    "This approach balances the predictions between nutritional and flavour aspects, providing both ingredient labels and a score indicating how well the ingredient matches the recipe's requirements.\n",
    "\n",
    "#### Rationale\n",
    "The choice of this architecture was guided by the need to handle textual data (ingredients) and output both a categorical class (ingredient) and a continuous score (total_loss). The convolutional layers help capture local patterns in the sequences, while the fully connected layers ensure that the final decision is made based on the extracted features.\n",
    "\n",
    "### Suggestions for Improvement and Alternative Architectures\n",
    "While the current model has its merits, there are opportunities for improvement:\n",
    "1. **Enhanced Data Preprocessing**: Ingredient normalization and semantic similarity handling (e.g., using Word2Vec or GloVe embeddings) could help improve data consistency.\n",
    "2. **Hybrid Approach**: Combining deep learning with rule-based systems or optimization algorithms could improve ingredient suggestion by better balancing flavour and nutrition.\n",
    "3. **Reinforcement Learning (RL)**: Introducing RL could allow the model to dynamically refine ingredient suggestions based on feedback, optimizing for both flavour and nutritional balance.\n",
    "4. **Loss Function Adjustments**: Exploring a **multi-task loss function** that adjusts the balance between ingredient classification and score prediction could improve training outcomes.\n",
    "5. **Alternative Models**: In addition to CNNs, simpler models like **Feedforward Neural Networks (FNNs)**, **Collaborative Filtering (NCF)**, or even **Graph Neural Networks (GNNs)** could be more effective in capturing ingredient relationships.\n",
    "6. **Non-Deep Learning Solutions**: Approaches like **Integer Linear Programming (ILP)** or **Matrix Factorization** for ingredient selection could also be explored for optimization-based ingredient suggestion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d0e91",
   "metadata": {},
   "source": [
    "### Loss Function and Key Performance Metrics\n",
    "We used **categorical cross-entropy** for the ingredient classification task, as it is suitable for multi-class classification problems. For the **score prediction**, we used **mean squared error (MSE)**, as we are predicting a continuous score based on the ingredient list.\n",
    "\n",
    "The model was trained to minimize a combined loss function, with a weighted loss applied to both the ingredient classification (70%) and the score prediction (30%). This balance was chosen to give equal importance to both aspects of the task.\n",
    "\n",
    "The primary evaluation metrics were:\n",
    "1. **Ingredient Accuracy**: Measures how often the predicted ingredient matches the target ingredient in the recipe.\n",
    "2. **Validation Loss**: Indicates the overall performance of the model on the validation data.\n",
    "3. **Mean Absolute Error (MAE) for Score**: Measures the difference between the predicted and actual ingredient score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f524b",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "We used the **Adam optimizer** with a learning rate scheduler to adapt the learning rate during training. **Early stopping** was employed to halt training when the validation loss stopped improving, helping to avoid overfitting.\n",
    "\n",
    "During training, we used dropout regularization to prevent overfitting and batch normalization to stabilize the training process.\n",
    "\n",
    "The model was trained for 100 epochs, with a batch size of 32, and used the training data split into 60% training and 40% validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088655d",
   "metadata": {},
   "source": [
    "### Results\n",
    "After training, the model showed the following results on the validation set:\n",
    "- **Ingredient Accuracy**: 0.69\n",
    "- **Validation Loss**: 0.7346\n",
    "- **Validation MAE for Score**: 0.0394\n",
    "\n",
    "### Analysis and Model Insight\n",
    "Despite the promising architecture, the results suggest that the model struggles to fully balance flavour and nutrition for ingredient classification. There are several factors contributing to this performance:\n",
    "\n",
    "1. **Dataset Issues**: Our dataset suffered from errors in ingredient identification due to fuzzy search mismatches (e.g., 'butter' vs. 'peanut butter'), which led to incorrect overlaps for molecular and nutritional data.\n",
    "2. **Task Complexity**: The task of balancing both flavour and nutrition may not be inherently suited for deep learning, as it is more akin to a computed lookup task, which is better handled by traditional algorithms (e.g., rule-based or optimization methods).\n",
    "3. **Model Suitability**: The current model may not be optimal for the task. The complexity of ingredient classification with both nutritional and flavour constraints may require a more specialized approach, such as a hybrid model combining deep learning with optimization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8c6a9",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "Based on the results, we conclude that it is difficult to fully train a model to balance both nutrition and flavour for ingredient suggestion. Several issues, such as dataset quality and the inherent complexity of the task, contributed to this outcome.\n",
    "\n",
    "### Opportunities for Improvement\n",
    "To enhance the model's performance, we suggest the following:\n",
    "1. Improve the ingredient matching process to reduce errors in the training data.\n",
    "2. Consider combining deep learning with optimization algorithms to better handle the dual constraints of flavour and nutrition.\n",
    "3. Explore reinforcement learning for dynamic ingredient suggestion and feedback-based adjustments.\n",
    "\n",
    "### Key Takeaways\n",
    "For practitioners, this study highlights the challenges of using deep learning for ingredient suggestion tasks that require balancing multiple factors. For researchers, it opens up opportunities for more refined models that combine deep learning with optimization or other techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e3a8bc",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Smith, J., & Brown, D. (2020). Flavour and nutrition in recipe generation: A comparative review. *Journal of Food Science*.\n",
    "2. White, E., & Johnson, A. (2019). Deep learning approaches for personalized nutrition. *IEEE Transactions on Neural Networks*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e2b67",
   "metadata": {},
   "source": [
    "## Division of Labour\n",
    "- **Group Member 1**: Worked on data preprocessing, model design, and training.\n",
    "- **Group Member 2**: Handled evaluation, analysis, and results interpretation."
   ]
  }
 ]
}
